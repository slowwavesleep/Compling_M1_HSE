{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtDKL88nBavZ",
        "colab_type": "text"
      },
      "source": [
        "2) На основе второй тетрадки  - https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/deep_pavlov_ner.ipynb\n",
        "Обучите Few-shot нейросеть на небольшом размеченном куске данных. Пример того, как должны быть размечены данные вы найдете вот тут – https://github.com/mannefedov/compling_nlp_hse_course/tree/master/data/few_shot\n",
        "Разметьте как минимум 10 разных предложений для train.txt Предложения в valid.txt и test.txt должны быть разными и не пересекаться с train.txt\n",
        "\n",
        "Проанализируйте результаты для каждого из методов (приводите конкретные примеры, не ссылайтесь на вывод ячеек с кодом – дублируйте нужное текстом в отдельной ячейке, старайтесь не утверждать очевидного – ищите что-нибудь интересное)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNyDDEgZJnSx",
        "colab_type": "text"
      },
      "source": [
        "# Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgJnlufqGjiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install deeppavlov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPk_2JwG-bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJSLtdJaHJup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!apt-get --yes install git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvcL4luHKR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install git+https://github.com/deepmipt/bert.git@feat/multi_gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbWQ9GN5HRJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly_KJGqsHOCg",
        "colab_type": "code",
        "outputId": "0dcdfbf5-8e75-4fd0-a48e-090087405b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbfLJ46oJH2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs, build_model, train_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyR55mt3JIgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with configs.ner.ner_ontonotes_bert_mult.open(encoding='utf8') as file:\n",
        "    ner_config = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR0hM8T2LFX-",
        "colab_type": "code",
        "outputId": "f33fe566-5e51-4708-bbc3-079ba45e6b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQVWlo46cHyN",
        "colab_type": "code",
        "outputId": "96f82305-5205-4942-d968-07de01865653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My Drive/colab_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/colab_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4h0rZ8cVo5O",
        "colab_type": "text"
      },
      "source": [
        "Файлы для обучения, валидации и тестирования в формате IOB. B маркирует начало сущности, а I продолжение. O - обозначает несущность."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV7ry_eaEcfd",
        "colab_type": "text"
      },
      "source": [
        "Текст в файле по всей видимости в некоторых случаях играет роль комментариев к фотографиям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2kIYpNZMGa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('pristavki.csv', header=None, names=['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnWUF-7TMIc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner_config['dataset_reader']['data_path'] = './'  # directory with train.txt, valid.txt and test.txt files\n",
        "ner_config['metadata']['variables']['NER_PATH'] = './'\n",
        "ner_config['metadata']['download'] = [ner_config['metadata']['download'][-1]]  # do not download the pretrained ontonotes model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uIc8GaSLZr_",
        "colab_type": "code",
        "outputId": "f2e71902-d31a-4b13-d41b-1d47c471a417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ner_model = train_model(ner_config, download=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:14:49.212 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 663M/663M [02:36<00:00, 4.23MB/s]\n",
            "2020-01-18 14:17:25.881 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2020-01-18 14:17:35.382 WARNING in 'deeppavlov.dataset_readers.conll2003_reader'['conll2003_reader'] at line 96: Skip 'WOLFCSTEIN:B-GAME\\n', splitted as ['WOLFCSTEIN:B-GAME']\n",
            "2020-01-18 14:17:35.391 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/trainers/nn_trainer.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2020-01-18 14:17:39.757 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/My Drive/colab_data/tag.dict]\n",
            "2020-01-18 14:17:40.216 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/My Drive/colab_data/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:18:13.869 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/My Drive/colab_data/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/colab_data/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:18:35.563 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 327 tokens with 41 phrases; found: 34 phrases; correct: 0.\n",
            "\n",
            "precision:  82.35%; recall:  68.29%; FB1:  74.67\n",
            "\n",
            "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tGAME: precision:  82.35%; recall:  70.00%; F1:  75.68 34\n",
            "\n",
            "\tGAMGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\n",
            "2020-01-18 14:18:35.568 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 74.6667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 8, \"metrics\": {\"ner_f1\": 74.6667, \"ner_token_f1\": 92.7835}, \"time_spent\": \"0:00:06\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:28:03.248 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 668 tokens with 79 phrases; found: 79 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tACC: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tGAME: precision:  100.00%; recall:  100.00%; F1:  100.00 74\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/trainers/nn_trainer.py:249: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "{\"train\": {\"eval_examples_count\": 16, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:09:34\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 320, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 1.5048099875450134}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:28:07.193 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 327 tokens with 41 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  73.68%; recall:  68.29%; FB1:  70.89\n",
            "\n",
            "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tACC: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tGAME: precision:  75.68%; recall:  70.00%; F1:  72.73 37\n",
            "\n",
            "\tGAMGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\n",
            "2020-01-18 14:28:07.508 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.6667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 8, \"metrics\": {\"ner_f1\": 70.8861, \"ner_token_f1\": 92.4623}, \"time_spent\": \"0:09:38\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 320, \"impatience\": 1, \"patience_limit\": 100}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:32:34.865 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/My Drive/colab_data/tag.dict]\n",
            "2020-01-18 14:33:03.340 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/My Drive/colab_data/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/colab_data/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:33:37.746 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 327 tokens with 41 phrases; found: 34 phrases; correct: 0.\n",
            "\n",
            "precision:  82.35%; recall:  68.29%; FB1:  74.67\n",
            "\n",
            "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tGAME: precision:  82.35%; recall:  70.00%; F1:  75.68 34\n",
            "\n",
            "\tGAMGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 8, \"metrics\": {\"ner_f1\": 74.6667, \"ner_token_f1\": 92.7835}, \"time_spent\": \"0:00:06\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:33:48.272 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 464 tokens with 51 phrases; found: 47 phrases; correct: 0.\n",
            "\n",
            "precision:  87.23%; recall:  80.39%; FB1:  83.67\n",
            "\n",
            "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tGAME: precision:  87.23%; recall:  80.39%; F1:  83.67 47\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 16, \"metrics\": {\"ner_f1\": 83.6735, \"ner_token_f1\": 91.7241}, \"time_spent\": \"0:00:11\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-18 14:33:49.74 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/My Drive/colab_data/tag.dict]\n",
            "2020-01-18 14:34:17.902 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/My Drive/colab_data/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/colab_data/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqSxlXEPAm-2",
        "colab_type": "text"
      },
      "source": [
        "Размеченные данные, использованные для обучения:\n",
        "* [test.txt](https://raw.githubusercontent.com/slowwavesleep/Compling_M1_HSE/master/HW4/test.txt)\n",
        "\n",
        "* [train.txt](https://raw.githubusercontent.com/slowwavesleep/Compling_M1_HSE/master/HW4/train.txt)\n",
        "\n",
        "* [valid.txt](https://raw.githubusercontent.com/slowwavesleep/Compling_M1_HSE/master/HW4/valid.txt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPmhpA1bSgwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "marked = []\n",
        "\n",
        "for text in data.text.values[:1000]:\n",
        "    if len(text.split()) > 100:\n",
        "        continue\n",
        "    pred = ner_model([text])\n",
        "    sent, tags = pred[0][0], pred[1][0]\n",
        "    \n",
        "    if len(set(tags[0])) > 1:\n",
        "        marked.append(list(zip(sent,tags)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ieDoAhTKXb",
        "colab_type": "code",
        "outputId": "1bf2cc2d-507f-44ac-b4ae-e792e8743ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "marked[45:47]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Watch', 'B-GAME'),\n",
              "  ('Dogs', 'I-GAME'),\n",
              "  ('2', 'I-GAME'),\n",
              "  ('Deluxe', 'I-GAME'),\n",
              "  ('Edition', 'I-GAME'),\n",
              "  ('-', 'O'),\n",
              "  ('1900', 'O'),\n",
              "  ('руб', 'O'),\n",
              "  ('.', 'O'),\n",
              "  ('/', 'O'),\n",
              "  ('\\n', 'O'),\n",
              "  (\"Assassin's\", 'B-GAME'),\n",
              "  ('Creed', 'I-GAME'),\n",
              "  ('Syndicate', 'I-GAME'),\n",
              "  ('-', 'O'),\n",
              "  ('1400', 'O'),\n",
              "  ('руб', 'O'),\n",
              "  ('.', 'O'),\n",
              "  ('/', 'O'),\n",
              "  ('\\n', 'O'),\n",
              "  ('UFC', 'B-GAME'),\n",
              "  ('-', 'O'),\n",
              "  ('800', 'O'),\n",
              "  ('руб', 'O'),\n",
              "  ('.', 'O'),\n",
              "  ('/', 'O'),\n",
              "  ('\\n', 'B-GAME'),\n",
              "  ('Destiny', 'I-GAME'),\n",
              "  ('The', 'I-GAME'),\n",
              "  ('Taken', 'I-GAME'),\n",
              "  ('King', 'I-GAME'),\n",
              "  ('-', 'O'),\n",
              "  ('1400', 'O'),\n",
              "  ('руб', 'O'),\n",
              "  ('.', 'O'),\n",
              "  ('/', 'O'),\n",
              "  ('\\n', 'O'),\n",
              "  ('Возможен', 'O'),\n",
              "  ('обмен', 'O'),\n",
              "  ('.', 'O')],\n",
              " [('Mortal', 'B-GAME'),\n",
              "  ('Kombat', 'I-GAME'),\n",
              "  ('X', 'I-GAME'),\n",
              "  ('(', 'O'),\n",
              "  ('Диск', 'O'),\n",
              "  ('для', 'O'),\n",
              "  ('Playstation', 'O'),\n",
              "  ('4', 'O'),\n",
              "  (')', 'O'),\n",
              "  ('/', 'O'),\n",
              "  ('\\n', 'O'),\n",
              "  ('Торга', 'O'),\n",
              "  ('и', 'O'),\n",
              "  ('обмена', 'O'),\n",
              "  ('нет', 'O')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBCgLRwiay8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1NYv1a4Jfpc",
        "colab_type": "text"
      },
      "source": [
        "# Анализ и сравнение результатов работы двух методов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyiKM3QLKcqv",
        "colab_type": "text"
      },
      "source": [
        "На мой взгляд, использование подхода, основанного на правилах, целесообразно, когда требуется выделять из текстов сравнительно узкий круг сущностей, например те же приставки. Для них сравнительно просто написать правила и учесть возможные ошибки. Игр же, в свою очередь, в сотни раз больше. Придумать универсальные правила, которые бы покрывали все франшизы у меня получилось. Например, использование правила, выбирающего слова, написанные латиницей, ухудшило результат, т.к. начало выбираться просто всё подряд. Думаю, дополнительно приводить примеры работы правилового подхода не имеет смысла, т.к. они, очевидно, определили только то, что я явным образом задал в правилах. Можно сказать, что данный подход даёт большую *точность*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiOLlIjRNDVh",
        "colab_type": "text"
      },
      "source": [
        "Использованная в данном ноутбуке модель, умеет выделять не только те сущности, которые не были заданы явным образом, но и те, которые были написаны с ошибкой или даже в транслитерации (!). Данный подход даёт большую *полноту*. Рассмотрим примеры ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0r4VH8eGW9j",
        "colab_type": "text"
      },
      "source": [
        "Не определилась третья игра. Думаю, связано с тем, что у неё в названии перемешаны русские и английские слова. Ведь обычно между ними есть четкая граница (лево|право), например, Название: Some Edition или Game: Сиквел.\n",
        "\n",
        "```\n",
        " [('Battlefield', 'B-GAME'),\n",
        "  ('4', 'I-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('Granturismo', 'B-GAME'),\n",
        "  ('3', 'I-GAME'),\n",
        "  ('и', 'O'),\n",
        "  ('Звезды', 'O'),\n",
        "  ('Playstation', 'O'),\n",
        "  ('Битва', 'O'),\n",
        "  ('сильнейших', 'O'),\n",
        "  ('.', 'O'),\n",
        "  ('За', 'O'),\n",
        "  ('все', 'O'),\n",
        "  ('1500', 'O'),\n",
        "  ('руб', 'O'),\n",
        "  ('.', 'O')]\n",
        "  ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCsMzruHBbj",
        "colab_type": "text"
      },
      "source": [
        "Антивирус определилися как игра. Легко объясняется тем, что софт в имеющихся данных находится в абсолютно тех же позициях (с дистрибутивной точки зрения), что и игры. Действительно, без учёта значения это очень сложно (или невозможно) определить.\n",
        "\n",
        "```\n",
        " ...\n",
        " [('Kaspersky', 'B-GAME'), # не игра вовсе\n",
        "  ('Anti', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('Virus', 'O'),\n",
        "  ('–', 'O'),\n",
        "  ('это', 'O'),\n",
        "  ('решение', 'O'),\n",
        "  ('для', 'O'),\n",
        "  ('базовой', 'O'),\n",
        "  ('защиты', 'O'),\n",
        "  ('компьютера', 'O'),\n",
        "  ('от', 'O'),\n",
        "  ('основных', 'O'),\n",
        "  ('видов', 'O'),\n",
        "  ('интернет', 'O'),\n",
        "  ('-', 'O'),\n",
        "  ('угроз', 'O'),\n",
        "  (',', 'O'),\n",
        "  ('не', 'O'),\n",
        "  ('снижающее', 'O'),\n",
        "  ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ1Ly19OHi7w",
        "colab_type": "text"
      },
      "source": [
        "Выявление сущностей, написанных с ошибками:\n",
        "\n",
        "```\n",
        " ...\n",
        " [('Assassins', 'B-GAME'),\n",
        "  ('creed', 'I-GAME'),\n",
        "  ('unity', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('800', 'O'),\n",
        "  ('₽', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('Bloodborn', 'B-GAME'), # неправильное написание\n",
        "  ('-', 'O'),\n",
        "  ('800', 'O'),\n",
        "  ('₽', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('Watch', 'B-GAME'),\n",
        "  ('dogs', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('800', 'O'),\n",
        "  ('₽', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('Wolfenstein', 'B-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('800', 'O'),\n",
        "  ('₽', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('MGS', 'B-GAME'),\n",
        "  ('5', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('1500', 'O'),\n",
        "  ('₽', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('The', 'B-GAME'),\n",
        "  ('last', 'I-GAME'),\n",
        "  ('of', 'I-GAME'),\n",
        "  ('us', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('1500', 'O'),\n",
        "  ('₽', 'O')]\n",
        "  ...\n",
        "\n",
        "  ...\n",
        "  ('Grand', 'B-GAME'), # неправильное написание\n",
        "  ('turismo', 'I-GAME'),\n",
        "  ('6', 'I-GAME')\n",
        "  ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTWFdCg3HnhA",
        "colab_type": "text"
      },
      "source": [
        "\"Зацепляется\" символ новой строки, расположенный рядом названием. Можно объяснить тем, что во многих объявлениях названия расположенны именно в столбик (и разделены как раз этим символом). Также определяет какие-то загадочные вещи, которые, судя по контексту, действительно являются играми.\n",
        "\n",
        "```\n",
        "...\n",
        "[('COLLAPSE', 'B-GAME'), # неизвестно что это вообще\n",
        "  (',', 'O'),\n",
        "  ('WARCRAFT', 'B-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('STALKER', 'B-GAME'),\n",
        "  ('(', 'O'),\n",
        "  ('ИСТОРИЯ', 'O'), # ??? но видимо тоже игра\n",
        "  ('ПРИБОЯ', 'O'),\n",
        "  (')', 'O'),\n",
        "  (',', 'O'),\n",
        "  ('WARRIOR', 'B-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'B-GAME'),\n",
        "  ('MАФИЯ', 'O'),\n",
        "  (',', 'O'),\n",
        "  ('ALONE', 'B-GAME'),\n",
        "  ('DARK', 'I-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('MERCENARIES2', 'B-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('SNIPER', 'B-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('ТАМПЛИЕРЫ', 'B-GAME'),\n",
        "  ('2', 'I-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'B-GAME'),\n",
        "  ('КВЕЙК4', 'O'),\n",
        "  (',', 'O'),\n",
        "  ('DEWIL', 'B-GAME'), # опять же неправильное написание\n",
        "  ('MAY', 'I-GAME'),\n",
        "  ('CRY', 'I-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('WORMS4', 'B-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('HOSPITAL', 'B-GAME'),\n",
        "  ('TYCOON', 'I-GAME'),\n",
        "  (',', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('FLASHPOINT', 'B-GAME'),\n",
        "  ('/', 'O'),\n",
        "  ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OxOJ6w7QQZ7",
        "colab_type": "text"
      },
      "source": [
        "Удивительным образом определяет транслитерированное название. Тут у меня нет объяснения.\n",
        "\n",
        "```\n",
        " ...\n",
        "[('Анчартед', 'B-GAME'),\n",
        "  ('4', 'I-GAME'),\n",
        "  ('-', 'O'),\n",
        "  ('2000', 'O'),\n",
        "  ('/', 'O'),\n",
        "  ('\\n', 'O'),\n",
        "  ('анчартид', 'O'),\n",
        "  ('коллекция', 'O'),\n",
        "  ('-', 'O'),\n",
        "  ('1500', 'O')]\n",
        "  ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hDJ5K5zQJfY",
        "colab_type": "text"
      },
      "source": [
        "Переводные названия оказывается не под силу, что странно, учитывая, что они имеют ровно ту же дистрибуцию, что и оригинальные названия. Можно также заметить, что символ переноса строки \"зацепляется\" далеко не всегда. Здесь опять же сложно найти объяснение.\n",
        "\n",
        "```\n",
        " ...\n",
        " ('Heavy', 'B-GAME'),\n",
        " ('rain', 'I-GAME'),\n",
        " ('-', 'O'),\n",
        " ('600', 'O'),\n",
        " ('р', 'O'),\n",
        " ('/', 'O'),\n",
        " ('\\n', 'O'),\n",
        " ('Uncharted', 'B-GAME'),\n",
        " ('3', 'I-GAME'),\n",
        " ('-', 'O'),\n",
        " ('900', 'O'),\n",
        " ('р', 'O'),\n",
        " ('/', 'O'),\n",
        " ('\\n', 'O'),\n",
        " ('За', 'O'),\n",
        " ('гранью', 'O'),\n",
        " ('-', 'O'),\n",
        " ('600', 'O'),\n",
        " ('р', 'O'),\n",
        " ('/', 'O'),\n",
        " ('\\n', 'O'),\n",
        " ('Одни', 'O'),\n",
        " ('из', 'O'),\n",
        " ('нас', 'O'),\n",
        " ('-', 'O'),\n",
        " ('900', 'O'),\n",
        " ('р', 'O'),\n",
        " ('/', 'O'),\n",
        " ('\\n', 'O'),\n",
        " ('Gta', 'B-GAME'),\n",
        " ('4', 'I-GAME'),\n",
        " ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5QxEOzQOXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}