{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Задание 1\n",
    "\n",
    "Основным модулем для работы с регулярными выражениями в питоне является re. Но есть ещё активно развивающийся regex. Найдите одно любое преимущество regex и опишите его, сопроводив примером (текст, на котором вы демонстрируете отличие, должен быть русским). Пользоваться можно любыми ресурсами, начните поиск с ссылок в семинарской тетрадке. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сматчить частично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex.compile(r'(ОШИБКА)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 4), match='ОШИБ', partial=True>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('ОШИБ', partial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('ОШИБ', partial=True).partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('ОШИБКА', partial=True).partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельный функционал, чтобы сматчить строку целиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pattern.fullmatch('НЕ ОШИБКА'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 6), match='ОШИБКА'>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.fullmatch('ОШИБКА')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pattern.fullmatch(' ОШИБКА '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень удобная штука, которая позволяет использовать f-строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это второе слово \"два\", а это первое \"раз\"'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.subf(r'(\\w+) (\\w+)', 'Это второе слово \"{2}\", а это первое \"{1}\"', \"раз два\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И нечеткий матчинг, само собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex.compile(r'(?:ОШИБКА){i}') # лишние символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 8), match='ДОБШИБКА', fuzzy_counts=(0, 2, 0)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('ДОБШИБКА')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex.compile(r'(?:ОШИБКА){e}') # ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 6), match='АШИПКА', fuzzy_counts=(2, 0, 0)>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('АШИПКА')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex.compile(r'(?:ОШИБКА){d}') # недостающие символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 5), match='ОШБКА', fuzzy_counts=(0, 0, 1)>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.match('ОШБКА')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать, чтобы находить в тексте слова, даже если в них есть ошибки. Пример тривиальный, но этого достаточно, чтобы продемонстрировать функционал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly_text = \"Мидвежата старше всех. Они радились еще холодной зимой в берлоги.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = regex.compile(r'(?:МЕДВЕЖАТА){e<=2}', flags=regex.IGNORECASE)\n",
    "pattern2 = regex.compile(r'(?:родились){e<=2}', flags=regex.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мидвежата']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern1.findall(silly_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' радились']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern2.findall(silly_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически такие же задачи можно решить и с помощью модуля ```re```, но на это потребуется существенно больше времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Задание 2\n",
    "\n",
    "Скачайте вот этот текст - http://gramota.ru/class/coach/punct/45_177\n",
    "\n",
    "Приведите его к нижнему регистру, удалите все знаки пунктуации, токенизируйте (любым способом). После этого сделайте стемминг и найдите по несколько примеров на каждый из видов ошибок:\n",
    "\n",
    "    1) два разных слова ошибочно свелись к одинаковой основе\n",
    "    2) две словоформы одного слова после стемминга отличаются друг от друга\n",
    "    3) слово не изменилось после стемминга (слово должно быть русским и длиннее 4 символов)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gramota.txt', encoding='utf-8') as file: # скопировал в файл, чтобы не забивать тетрадку\n",
    "    gramota = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramota = gramota.replace('\\n', ' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'выберите правильные варианты ответов. для проверки выполненного задания нажмите кнопку «проверить».   обособление обстоятельств обстоятельство – второстепенный член предложения, который обозначает признак действия или другого признака. обстоятельства поясняют'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gramota[:259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramota = nltk.word_tokenize(gramota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramota = [word.strip('_') for word in gramota if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['выберите', 'правильные', 'варианты', 'ответов', 'для']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gramota[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.snowball.SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = [(word, stemmer.stem(word)) for word in gramota]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  1) два разных слова ошибочно свелись к одинаковой основе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_stems = set([stem for word, stem in stems])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(846, 425)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stems), len(only_stems) #основ очевидно меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems_reverse = {}\n",
    "for key, value in stems:\n",
    "    stems_reverse.setdefault(value, set()).add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('обстоятельств', {'обстоятельств', 'обстоятельства', 'обстоятельство'}),\n",
       " ('член', {'член', 'члены'}),\n",
       " ('предложен', {'предложении', 'предложения', 'предложениях'}),\n",
       " ('котор', {'которые', 'который'}),\n",
       " ('признак', {'признак', 'признака'}),\n",
       " ('друг', {'другие', 'другого'}),\n",
       " ('сказуем', {'сказуемые', 'сказуемым'}),\n",
       " ('выделя', {'выделяется', 'выделять', 'выделяются'}),\n",
       " ('случа', {'случае', 'случаи', 'случай', 'случаях'}),\n",
       " ('рассмотр', {'рассмотрим', 'рассмотрите'})]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, value) for key, value in stems_reverse.items() if len(value) > 1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например,\n",
    "<ul>\n",
    "    <li>('вид', {'вид', 'видит', 'видов'})</li>\n",
    "    <li>('выражен', {'выражением', 'выраженные'})</li>\n",
    "    <li> ('цел', {'цели', 'целый', 'целью'})</li>\n",
    "</ul>\n",
    "\n",
    "По-моему, ошибок не так много, учитывая ограничения метода. Не во всех случаях вообще можно без контекста оценить ошибочность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) две словоформы одного слова после стемминга отличаются друг от друга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('выберите', 'выбер'),\n",
       " ('правильные', 'правильн'),\n",
       " ('варианты', 'вариант'),\n",
       " ('ответов', 'ответ'),\n",
       " ('для', 'для'),\n",
       " ('проверки', 'проверк'),\n",
       " ('выполненного', 'выполнен'),\n",
       " ('задания', 'задан'),\n",
       " ('нажмите', 'нажм'),\n",
       " ('кнопку', 'кнопк')]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('деепричастием', 'деепричаст'),\n",
       " ('деепричастий', 'деепричаст'),\n",
       " ('деепричастным', 'деепричастн'),\n",
       " ('молча', 'молч'),\n",
       " ('обозначает', 'обознача'),\n",
       " ('отвечают', 'отвеча'),\n",
       " ('отвечающие', 'отвеча'),\n",
       " ('отличать', 'отлича'),\n",
       " ('примечаний', 'примечан'),\n",
       " ('скучал', 'скуча'),\n",
       " ('случае', 'случа'),\n",
       " ('случаи', 'случа'),\n",
       " ('случай', 'случа'),\n",
       " ('случая', 'случ'),\n",
       " ('случаях', 'случа'),\n",
       " ('торчал', 'торча'),\n",
       " ('часов', 'час'),\n",
       " ('частями', 'част'),\n",
       " ('чаще', 'чащ')}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([(word, stem) for word, stem in stems if 'ча' in word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь тоже не очень много примеров.\n",
    "<ul>\n",
    "    <li>('сидел', 'сидел') – ('сидя', 'сид')</li>\n",
    "    <li>('случая', 'случ') – ('случаях', 'случа')</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) слово не изменилось после стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "case3 = set([stem for stem in stems if len(stem[0]) > 4 and stem[0] == stem[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('будет', 'будет'),\n",
       " ('вдруг', 'вдруг'),\n",
       " ('взмахнув', 'взмахнув'),\n",
       " ('видел', 'видел'),\n",
       " ('воннегут', 'воннегут'),\n",
       " ('вопрос', 'вопрос'),\n",
       " ('встает', 'встает'),\n",
       " ('выйдет', 'выйдет'),\n",
       " ('вынырнул', 'вынырнул'),\n",
       " ('город', 'город'),\n",
       " ('дворник', 'дворник'),\n",
       " ('имеет', 'имеет'),\n",
       " ('могут', 'могут'),\n",
       " ('может', 'может'),\n",
       " ('мороз', 'мороз'),\n",
       " ('например', 'например'),\n",
       " ('оборот', 'оборот'),\n",
       " ('обстоятельств', 'обстоятельств'),\n",
       " ('перед', 'перед'),\n",
       " ('подряд', 'подряд'),\n",
       " ('пошел', 'пошел'),\n",
       " ('признак', 'признак'),\n",
       " ('пушкин', 'пушкин'),\n",
       " ('сидел', 'сидел'),\n",
       " ('сотрудник', 'сотрудник'),\n",
       " ('сумел', 'сумел'),\n",
       " ('хотел', 'хотел'),\n",
       " ('через', 'через')}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Задание 3\n",
    "Проанализируйте список стоп-слов из нлтк (для русского). Какие ещё слова вы бы туда добавили? (5 слов будет достаточно, не забудьте аргументировать ваш выбор)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список состоит из наречий, местоимений, частиц, но он, очевидно, не полный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_stopwords[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cтоит проанализировать покрытие какого-нибудь текста имеющимися стоп-словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('war_and_peace.txt', encoding='utf-8') as file:\n",
    "    war_and_peace = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace = nltk.word_tokenize(war_and_peace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace = [word.lower() for word in war_and_peace if word.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого посмотрим на наиболее частотные слова, уже отфильтрованные по списку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace = collections.Counter(war_and_peace).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [word for word, freq in war_and_peace if word not in nltk_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['это',\n",
       " 'сказал',\n",
       " 'пьер',\n",
       " 'князь',\n",
       " 'сноска',\n",
       " 'наташа',\n",
       " 'андрей',\n",
       " 'время',\n",
       " 'сказала',\n",
       " 'которые']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный результат содержит много частиц, местоимений и местоимений-прилагательных. Если слова в тексте рассматривать изолированно, то их можно отнести к неинформативным. Разные формы последних составляют существенный объём текста. Предлагаю добавить их, но всё же отмечу, что не в каждой задаче это будет правильными решением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = ('это', 'который', 'этих', 'тех', 'свой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for word in suggestion: print(word in nltk_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополним имеющийся список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords.extend(suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Задание 4\n",
    "\n",
    "Скачайте вот этот текст - https://zona.media/news/2019/09/11/zhukov-expertise\n",
    "\n",
    "Предобработайте текст двумя способами:\n",
    "1) Разбейте текст на предложения sent_tokenize из nltk, токенизируйте каждое предложение с помощью регулярного выражения (попробуйте разные и выберите лучшее), лемматизируйте токены с помощью pymorphy2\n",
    "\n",
    "2) предобработайте текст с помощью mystem3 \n",
    "\n",
    "Ответьте на вопросы:\n",
    "1) Что лучше разбивает на предложения (mystem или sent_tokenize)?\n",
    "2) Что лучше токенизирует (mystem или ваша регулярка)? Если mystem, то можно ли улучшить регулярное выражение так, чтобы качество было выше?\n",
    "3) Что лучше для лемматизации mystem или pymorphy?\n",
    "\n",
    "Важно, чтобы ответы на вопросы были аргументированы. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pymorphy2 + nltk + re*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('zhuk.txt', encoding='utf-8') as file:\n",
    "    zhuk = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhuk = zhuk.replace('\\n', ' ').replace('\\u200b', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhuk_pym = nltk.sent_tokenize(zhuk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'([А-Яа-яA-Za-z]+-*[А-Яа-я]*-*[А-Яа-я]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_re = []\n",
    "for sent in zhuk_pym:\n",
    "    words_re.extend(re.findall(pattern, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['перевел', 'студента', 'под', 'домашний', 'арест']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_re[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pym = [pymorph.parse(word)[0][2] for word in words_re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['перевести', 'студент', 'под', 'домашний', 'арест']"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_pym[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*mystem3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл получен путём обработки текста бинарным файлом, поскольку доступа к функционалу с разбивкой на предложения через Python  нет\n",
    "```\n",
    "./mystem -iscd --format json zhuk.txt zhuk_sent.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('zhuk_sent.txt', encoding='utf-8') as file:\n",
    "    zhuk_sent = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_mys = []\n",
    "for paragraph in zhuk_sent:\n",
    "    current = [word['text'] for word in paragraph]\n",
    "    current = ''.join(current).strip('\\r\\n').split('\\\\s')\n",
    "    sents_mys.extend(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку лемматизация уже проведёна и доступна в самом файле, получим эти данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_mys = []\n",
    "for paragraph in zhuk_sent:\n",
    "    lemmas_mys.extend([word['analysis'][0]['lex'] for word in paragraph if 'analysis' in word.keys() and word['analysis']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['переводить', 'студент', 'под', 'домашний', 'арест']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_mys[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случаях анализтор не понимает, что текст, не отделённый точкой или другим знаком препинания, завершающим предложение, но отделённый знаком переноса строки, в начале файла может быть его заголовком. Пришлось его убрать для чистоты эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1) Что лучше разбивает на предложения (mystem или sent_tokenize)?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По предложениям получаем одинаковую разбивку :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhuk_pym[-1] == sents_mys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zhuk_pym) == len(sents_mys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница только в том, что на вариант с mystem пришлось потрать больше времени и сил, поэтому мой голос в пользу **sent_tokenize**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2) Что лучше токенизирует (mystem или ваша регулярка)? Если mystem, то можно ли улучшить регулярное выражение так, чтобы качество было выше?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь опять же получился одинаковый результат. Регулярка вполне адекватно справилась, написать её было проще, чем разобраться в многоуровневой вложенности списков и словарей mystem.\n",
    "\n",
    "Единственный минус регулярки оказался в том, в результате потерялся \"yotube\" из \"youtube-канал\". Улучшить её можно, добавив и латиницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['По',\n",
       " 'ходатайстве',\n",
       " 'следствие',\n",
       " 'суд',\n",
       " 'перевел',\n",
       " 'студента',\n",
       " 'под',\n",
       " 'домашний',\n",
       " 'арест']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_re[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По ходатайстве следствие суд перевел студента под домашний арест.'"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_mys[-1] #предложение собрано из отдельных токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "3) Что лучше для лемматизации mystem или pymorphy?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты получились схожие, за исключением:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pymorphy предпочитает совершенный вид, а mystem несовершенный\n",
    "* единственное упущение pymorphy – \"сизый\", а не \"сизо\"\n",
    "* малозначительное разделение \"о\" и \"об\"\n",
    "* pymorphy выделяет \"она\" как лемму \"её\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('перевести', 'переводить'),\n",
       " ('студент', 'студент'),\n",
       " ('под', 'под'),\n",
       " ('домашний', 'домашний'),\n",
       " ('арест', 'арест')]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words_pym, lemmas_mys))[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мой голос в пользу **pymorphy**, т.к. использовать его было проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резюмируя, можно сказать, что на данном тексте действительно получаются довольно близкие результаты, но это не значит, что на каком-то другом тексте у mystem не будет бы преимущества, при этом будет ли это преимущество оправдывать неудобство использования – отдельный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
