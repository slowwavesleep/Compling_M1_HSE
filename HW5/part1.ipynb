{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основаная задача - **построить хорошую тематическую модель с интерпретируемыми топиками с помощью LDA в gensim и NMF в sklearn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраните тетрадку с экспериментами и положите её на гитхаб, ссылку на неё укажите в форме.\n",
    "\n",
    "**Оцениваться будут главным образом пункты 5, 8 и 10. (2, 3, 2 баллов соответственно). Чтобы заработать остальные 3 балла, нужно хотя бы немного изменить мой код на промежуточных этапах (добавить что-то, указать другие параметры и т.д). **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) сделайте нормализацию (если pymorphy2 работает долго используйте mystem или попробуйте установить быструю версию - `pip install pymorphy2[fast]`, можно использовать какой-то другой токенизатор); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('habr_texts.txt', encoding='utf-8') as file:\n",
    "    source = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решил оставить только слова написанные кирилицей, поскольку в статьях много кода, который никак не отделён от основного текста. Попытки оставить только \"полезные\" слова вроде названий языков программирования, фреймворков и прочего непропорционально усложняют решение, при этом, по ощущения, полезнее убрать код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian')) | {'gt',}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'{[^}]+}', ' ', text)\n",
    "    text = re.sub(r'\\&[a-z]+\\;', ' ', text)\n",
    "    text = text.replace('\\t', ' ')\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'[А-Яа-я]+', text)\n",
    "\n",
    "# чтобы быстрее нормализовать тексты, создадим словарь всех словоформ\n",
    "# нормазуем каждую 1 раз и положим в словарь\n",
    "# затем пройдем по текстам и сопоставим каждой словоформе её нормальную форму\n",
    "\n",
    "def opt_normalize(texts, top=None):\n",
    "    uniq = Counter()\n",
    "    for text in texts:\n",
    "        uniq.update(text)\n",
    "    \n",
    "    norm_uniq = {word:morph.parse(word)[0].normal_form for word, _ in uniq.most_common(top)}\n",
    "    \n",
    "    norm_texts = []\n",
    "    for text in texts:\n",
    "        \n",
    "        norm_words = [norm_uniq.get(word) for word in text]\n",
    "        norm_words = [word for word in norm_words if word and word not in stop_words]\n",
    "        norm_texts.append(norm_words)\n",
    "        \n",
    "    return norm_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) добавьте нграммы (в тетрадке есть закомменченая ячейка с Phrases,  можно также попробовать другие способы построить нграммы); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = opt_normalize([tokenize(clean_text(text)) for text in source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = gensim.models.Phrases(texts, scoring='npmi', min_count=8, threshold=0.2)\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) сделайте хороший словарь (отфильтруйте слишком частотные и редкие слова, попробуйте удалить стоп-слова); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(ngrammed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_above=0.1, no_below=15)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) постройте несколько LDA моделей (переберите количество тем, можете поменять alpha, passes), если получаются плохие темы, поработайте дополнительно над предобработкой и словарем; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=5, passes=3, alpha='asymmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"камера\" + 0.002*\"смартфон\" + 0.002*\"сигнал\" + 0.002*\"продажа\" + 0.002*\"товар\" + 0.001*\"услуга\" + 0.001*\"диск\" + 0.001*\"звук\" + 0.001*\"контроллер\" + 0.001*\"принтер\"'),\n",
       " (1,\n",
       "  '0.002*\"переменный\" + 0.002*\"программирование\" + 0.002*\"курс\" + 0.001*\"ядро\" + 0.001*\"шаблон\" + 0.001*\"компилятор\" + 0.001*\"сборка\" + 0.001*\"протокол\" + 0.001*\"оператор\" + 0.001*\"бот\"'),\n",
       " (2,\n",
       "  '0.003*\"телефон\" + 0.002*\"массив\" + 0.002*\"символ\" + 0.002*\"браузер\" + 0.002*\"вектор\" + 0.001*\"бот\" + 0.001*\"переменный\" + 0.001*\"перевод\" + 0.001*\"раздел\" + 0.001*\"книга\"'),\n",
       " (3,\n",
       "  '0.003*\"ядро\" + 0.002*\"процессор\" + 0.002*\"робот\" + 0.002*\"глаз\" + 0.001*\"город\" + 0.001*\"ребёнок\" + 0.001*\"звук\" + 0.001*\"книга\" + 0.001*\"инструкция\" + 0.001*\"мозг\"'),\n",
       " (4,\n",
       "  '0.004*\"игрок\" + 0.002*\"браузер\" + 0.002*\"ключ\" + 0.001*\"узел\" + 0.001*\"земля\" + 0.001*\"клетка\" + 0.001*\"пароль\" + 0.001*\"анимация\" + 0.001*\"движение\" + 0.001*\"домен\"')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaModel(corpus, id2word=dictionary, eval_every=1, num_topics=5, passes=3, alpha='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"боль\" + 0.005*\"домен\" + 0.004*\"головка\" + 0.004*\"инцидент\" + 0.004*\"печать\" + 0.004*\"пароль\" + 0.004*\"атака\" + 0.003*\"уязвимость\" + 0.003*\"клетка\" + 0.003*\"принтер\"'),\n",
       " (1,\n",
       "  '0.005*\"браузер\" + 0.004*\"массив\" + 0.004*\"контекст\" + 0.003*\"шаблон\" + 0.003*\"атрибут\" + 0.003*\"бот\" + 0.003*\"переменный\" + 0.003*\"логика\" + 0.003*\"кампания\" + 0.003*\"контейнер\"'),\n",
       " (2,\n",
       "  '0.008*\"игрок\" + 0.004*\"студент\" + 0.003*\"мозг\" + 0.003*\"играть\" + 0.003*\"дом\" + 0.003*\"звук\" + 0.003*\"доклад\" + 0.003*\"курс\" + 0.002*\"электроника\" + 0.002*\"аудитория\"'),\n",
       " (3,\n",
       "  '0.005*\"вакансия\" + 0.004*\"ядро\" + 0.003*\"яркость\" + 0.003*\"стандарт\" + 0.003*\"сигнал\" + 0.003*\"дефект\" + 0.003*\"процессор\" + 0.003*\"цикл\" + 0.003*\"узел\" + 0.003*\"диск\"'),\n",
       " (4,\n",
       "  '0.008*\"услуга\" + 0.005*\"заказчик\" + 0.002*\"продажа\" + 0.002*\"российский\" + 0.002*\"трафик\" + 0.002*\"предприятие\" + 0.002*\"публикация\" + 0.002*\"реклама\" + 0.002*\"китай\" + 0.002*\"инвестиция\"')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) для самой хорошей модели в отдельной ячейке напечатайте 3 хороших (на ваш вкус) темы;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) между словарем и обучением модели добавьте tfidf (`gensim.models.TfidfModel(corpus, id2word=dictionary); corpus = tfidf[corpus]`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) повторите пункт 4 на преобразованном корпусе;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=5, passes=3, alpha='asymmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"игрок\" + 0.001*\"браузер\" + 0.001*\"доклад\" + 0.001*\"ключ\" + 0.001*\"бот\" + 0.001*\"камера\" + 0.001*\"ядро\" + 0.001*\"смартфон\" + 0.001*\"книга\" + 0.001*\"диск\"'),\n",
       " (1,\n",
       "  '0.001*\"бот\" + 0.001*\"книга\" + 0.000*\"телефон\" + 0.000*\"робот\" + 0.000*\"камера\" + 0.000*\"дом\" + 0.000*\"сколько_часы\" + 0.000*\"браузер\" + 0.000*\"фотография\" + 0.000*\"стартап\"'),\n",
       " (2,\n",
       "  '0.000*\"игрок\" + 0.000*\"кампания\" + 0.000*\"ядро\" + 0.000*\"письмо\" + 0.000*\"бот\" + 0.000*\"мониторинг\" + 0.000*\"блокировка\" + 0.000*\"хакатон\" + 0.000*\"рецепт\" + 0.000*\"рис\"'),\n",
       " (3,\n",
       "  '0.000*\"врач\" + 0.000*\"блокировка\" + 0.000*\"сообщение_ошибка\" + 0.000*\"браузер\" + 0.000*\"бэкап\" + 0.000*\"лекция\" + 0.000*\"дефект\" + 0.000*\"домен\" + 0.000*\"менеджер\" + 0.000*\"р\"'),\n",
       " (4,\n",
       "  '0.000*\"плагин\" + 0.000*\"локализация\" + 0.000*\"профиль\" + 0.000*\"родной_язык\" + 0.000*\"флаг\" + 0.000*\"панель\" + 0.000*\"станок\" + 0.000*\"шапка\" + 0.000*\"синтезатор\" + 0.000*\"социальный_сеть\"')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, id2word=dictionary, eval_every=1, num_topics=5, passes=3, alpha='asymmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"игрок\" + 0.001*\"браузер\" + 0.001*\"бот\" + 0.001*\"доклад\" + 0.001*\"ядро\" + 0.001*\"ключ\" + 0.001*\"книга\" + 0.001*\"камера\" + 0.001*\"смартфон\" + 0.001*\"диск\"'),\n",
       " (1,\n",
       "  '0.000*\"письмо\" + 0.000*\"камера\" + 0.000*\"книга\" + 0.000*\"бот\" + 0.000*\"драйвер\" + 0.000*\"игрок\" + 0.000*\"подложка\" + 0.000*\"ключ\" + 0.000*\"переменный\" + 0.000*\"робот\"'),\n",
       " (2,\n",
       "  '0.000*\"доклад\" + 0.000*\"игрок\" + 0.000*\"вм\" + 0.000*\"никак_влиять\" + 0.000*\"звук\" + 0.000*\"высокий_вероятность\" + 0.000*\"хост\" + 0.000*\"сборка\" + 0.000*\"кластер\" + 0.000*\"виртуальный_машина\"'),\n",
       " (3,\n",
       "  '0.000*\"вселенная\" + 0.000*\"инфляция\" + 0.000*\"биткоина\" + 0.000*\"рабочий_стол\" + 0.000*\"дерево\" + 0.000*\"сегментация\" + 0.000*\"вебинар\" + 0.000*\"всплывать_окно\" + 0.000*\"скидка\" + 0.000*\"энергия\"'),\n",
       " (4,\n",
       "  '0.000*\"собеседование\" + 0.000*\"сокет\" + 0.000*\"симулятор\" + 0.000*\"ядро\" + 0.000*\"метрика\" + 0.000*\"ндс\" + 0.000*\"папка\" + 0.000*\"мастер\" + 0.000*\"робот\" + 0.000*\"вектор\"')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) в отдельной ячейке опишите как изменилась модель (приведите несколько тем, которые стали лучше или хуже, или которых раньше вообще не было; можно привести значения перплексии и когерентности для обеих моделей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) проделайте такие же действия для NMF (образец в конце тетрадки), для построения словаря воспользуйтесь возможностями Count или Tfidf Vectorizer (попробуйте другие значение max_features, min_df, max_df, сделайте нграмы через ngram_range, если хватает памяти), попробуйте такие же количества тем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) в отдельной ячейки напечатайте темы лучшей NMF модели, сравните их с теми, что получились в LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
