{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1. (5 баллов) \n",
    "В тетрадке реализована биграмная языковая модель (при генерации учитывается информация только о 1 предыдущем слове). Реализуйте триграмную модель и сгенерируйте несколько текстов. Сравните их с текстами, сгенерированными биграмной моделью. \n",
    "Можно использовать те же тексты, что в семинаре, или взять какой-то другой (на английском или русском языке).  \n",
    "\n",
    "Делать это задание будет легче после прочтения первых 7 страниц вот этой главы из Журафского - https://web.stanford.edu/~jurafsky/slp3/3.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import copy\n",
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stranger.txt', encoding='utf-8') as file: #Robert Heinlein's Stranger in a Strange Land with preface removed\n",
    "    stranger = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stranger = stranger.replace('“Stranger In A Strange Land” by Robert Heinlein', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.tokenize.sent_tokenize(stranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'([A-Za-z]+[\\'-]?[A-Za-z]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [re.findall(pattern, sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in sents:\n",
    "    for w1, w2, w3 in nltk.trigrams(sentence, pad_right=True, pad_left=True, left_pad_symbol='<s>', right_pad_symbol='</s>'):\n",
    "        tri_model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логарифм не использую, потому что верятности нужны только, чтобы сделать взвешенную выборку, а не чтобы их глазами сравнивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bigram in tri_model:\n",
    "    total_count = sum(tri_model[bigram].values())\n",
    "    for target in tri_model[bigram]:\n",
    "        tri_model[bigram][target] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_generate(model, start=('<s>', '<s>')):\n",
    "    text = list(start)\n",
    "    while text[-1] != '</s>': \n",
    "        index = tuple(text[-2:])\n",
    "        keys = list(model[index].keys())\n",
    "        values = list(model[index].values())\n",
    "        key = np.random.choice(keys, 1, values)[0]\n",
    "        text.append(key)\n",
    "    return ' '.join(text[2:]).strip(' </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generator(sent_generator, model, number_of_sents=1, count_words=False):\n",
    "    result = []\n",
    "    for _ in range(number_of_sents):\n",
    "        result.append(sent_generator(model))\n",
    "       \n",
    "    if count_words == True:\n",
    "        count = count_words_avg(result)\n",
    "        return count\n",
    "    else:\n",
    "        result = '. '.join(result) + '.'\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_avg(sents):\n",
    "    total = 0\n",
    "    for sent in sents:\n",
    "        total += len(sent.split(' '))\n",
    "    return total/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We call her over. repeated Jill. Hypothetical situation for you wench Miriam insisted. Mnimm on Mars which we can judge his virtue- virtue so great mind you that would show up for sale but they seemed like gun. Eternity is no cure short of breaking him on the spot while it's hot- your newscaster Happy Holliday Went on as before. grabbed his ear pulled him gently to Jill cupped a handful of water brother said breathlessly.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_example = text_generator(tri_generate, tri_model, 6)\n",
    "tri_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in sents:\n",
    "    for w1, w2 in nltk.bigrams(sentence, pad_right=True, pad_left=True, left_pad_symbol='<s>', right_pad_symbol='</s>'):\n",
    "        bi_model[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unigram in bi_model:\n",
    "    total_count = sum(bi_model[unigram].values())\n",
    "    for target in bi_model[unigram]:\n",
    "        bi_model[unigram][target] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_generate(model, start=['<s>']):\n",
    "    text = copy.deepcopy(start)\n",
    "    while text[-1] != '</s>': \n",
    "        index = text[-1]\n",
    "        keys = list(model[index].keys())\n",
    "        values = list(model[index].values())\n",
    "        key = np.random.choice(keys, 1, values)[0]\n",
    "        text.append(key)\n",
    "    return ' '.join(text[1:]).strip(' </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Duke-where s stop worrying about another channel then searched in anyone would again rose hushe. Suddenly she pleased mood from his oath that Martians haven't estimated at hand in seeing it difficult and won't his shoulder shoved back stood alone-a slender young fellows seem. Through your eyes-no violence brutality-but it sent back later maybe priestess-it can dig him become untired. Thirty minutes had whether or at Berkeley and Jiib with equal. t count is no purpose-Dr Nelson long pauses some religion before with more aggressive. Feeling better by ancestry.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_example = text_generator(bi_generate, bi_model, 6)\n",
    "bi_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат триграммной модели для сравнения: <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We call her over. repeated Jill. Hypothetical situation for you wench Miriam insisted. Mnimm on Mars which we can judge his virtue- virtue so great mind you that would show up for sale but they seemed like gun. Eternity is no cure short of breaking him on the spot while it's hot- your newscaster Happy Holliday Went on as before. grabbed his ear pulled him gently to Jill cupped a handful of water brother said breathlessly.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отметить две вещи: <br>\n",
    "1) Предложения, созданные триграммной модели определённо больше похожи на текст, написанный человеком. Они более связные (только грамматически, естественно). <br>\n",
    "2) Биграммные предложения длиннее, чем триграммные, при условии, что мы останавливаемся только на символе окончания предложения. Это подтверждается экспериментом ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bigram model sentence length: 19.81 words\n",
      "Average trigram model sentence length: 12.93 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "m = 10\n",
    "bi_test = 0\n",
    "tri_test = 0\n",
    "for _ in range(n):\n",
    "    bi_test += text_generator(bi_generate, bi_model, m, count_words=True)\n",
    "    tri_test += text_generator(tri_generate, tri_model, m, count_words=True)\n",
    "print(f'Average bigram model sentence length: {bi_test/n:.2f} words\\n' +\n",
    "      f'Average trigram model sentence length: {tri_test/n:.2f} words\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2. (5 баллов) \n",
    "При помощи gensim.models.Phrases реализуйте byte-pair-encoding, про который говорилось на первом семинаре (https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/Preprocessing.ipynb) \n",
    "А именно 1) возьмите любой текст; разбейте его на предложения, а каждое предложение разбейте на отдельные символы (не потеряйте пробелы) 2) обучите gensim.models.Phrases на полученных символьных предложениях 3) примените полученный нграммер к этим символьным предложениям 4) повторите 2 и 3 N количество раз, чтобы начали получаться целые слова\n",
    "Параметры в gensim.models.Phrases влияют на количество получаемых нграммов после каждого прохода, поэтому не забудьте их настроить\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_sents = [' '.join(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_sents = [[ch for ch in sent if ch not in ',.;!?\\n'] for sent in symbol_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases1 = Phrases(symbol_sents, scoring='npmi', threshold=1, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases2 = Phrases(phrases1[symbol_sents], scoring='npmi', threshold=0, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases3 = Phrases(phrases2[symbol_sents], scoring='npmi', threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_a_r',\n",
       " 't_ _o_n',\n",
       " 'e_ _H',\n",
       " 'I_S',\n",
       " ' _M_A',\n",
       " 'C_U_L_A',\n",
       " 'T_E_ _O',\n",
       " 'R_I_G',\n",
       " 'I_N_ _I',\n",
       " ' _O_N_C',\n",
       " 'E_ _U',\n",
       " 'P_O_N',\n",
       " ' _A_ _T',\n",
       " 'I_M_E',\n",
       " ' _w_h_e',\n",
       " 'n_ _t_h',\n",
       " 'e_ _w_o',\n",
       " 'r_l_d',\n",
       " ' _w_a_s',\n",
       " ' _y_o_u',\n",
       " 'n_g_ _t',\n",
       " 'h_e_r_e',\n",
       " ' _w_a_s',\n",
       " ' _a_ _M',\n",
       " 'a_r_t_i',\n",
       " 'a_n_ ',\n",
       " 'n_a_m',\n",
       " 'e_d_ _S',\n",
       " 'm_i_t_h']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(phrases3[phrases2[phrases1[symbol_sents]]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
